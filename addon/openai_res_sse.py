import logging
import json
from typing import Any, List, Dict, Tuple
import traceback

from mitmproxy.contentviews._api import Contentview
from mitmproxy import contentviews
from mitmproxy.http import Response


def multi_line_splitter(line: int) -> str:
    """ç”Ÿæˆåˆ†å‰²çº¿"""
    return "\n " * line + "\n"


def indent_text(text: str, n: int) -> str:
    """å°†å¤šè¡Œæ–‡æœ¬æ•´ä½“ç¼©è¿› n ä¸ªç©ºæ ¼"""
    indent = " " * n
    # ç¡®ä¿åœ¨ç¼©è¿›å‰å…ˆå°è¯•ç¾åŒ–JSONå­—ç¬¦ä¸²
    try:
        parsed_json = json.loads(text)
        text = json.dumps(parsed_json, indent=4, ensure_ascii=False)
    except json.JSONDecodeError:
        # å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„JSONï¼Œåˆ™ä¿æŒåŸæ ·
        pass
    indented_lines = [
        (indent + line) if line.strip() else line for line in text.splitlines()
    ]
    return "\n".join(indented_lines)


split_line = "\n----------------------------------\n"


def handle_response_basis(body: Dict[str, Any]) -> str:
    """å¤„ç†å“åº”çš„åŸºç¡€ä¿¡æ¯: model, object, usage"""
    basic_result = ""
    model = body.get("model", "N/A")
    object_type = body.get("object", "N/A")

    # è·å–tokenä½¿ç”¨æƒ…å†µ
    id = body.get("id", "N/A")
    usage = body.get("usage", {})
    prompt_tokens = usage and usage.get("prompt_tokens", "N/A")
    completion_tokens = usage and usage.get("completion_tokens", "N/A")
    total_tokens = usage and usage.get("total_tokens", "N/A")

    # è®¡ç®—æ‰€æœ‰æ ‡ç­¾çš„æœ€å¤§é•¿åº¦ï¼Œå®ç°å³å¯¹é½
    labels = [
        "id",
        "model",
        "object",
        "prompt_tokens",
        "completion_tokens",
        "total_tokens",
    ]
    max_label_len = max(len(label) for label in labels) + 2

    basic_result += f'{"id":<{max_label_len}}:   {id}\n'
    basic_result += f'{"model":<{max_label_len}}:   {model}\n'
    basic_result += f'{"object":<{max_label_len}}:   {object_type}\n'
    basic_result += f'{"prompt_tokens":<{max_label_len}}:   {prompt_tokens}\n'
    basic_result += f'{"completion_tokens":<{max_label_len}}:   {completion_tokens}\n'
    basic_result += f'{"total_tokens":<{max_label_len}}:   {total_tokens}\n'

    return basic_result


def handle_system_fingerprint(body: Any) -> str:
    """å¤„ç†ç³»ç»ŸæŒ‡çº¹ä¿¡æ¯"""
    system_fingerprint = body.get("system_fingerprint", None)
    if system_fingerprint:
        return f"## System FingerprintğŸ”‘\n{system_fingerprint}\n"
    return ""


def parse_sse_data(data: bytes) -> List[Dict[str, Any]]:
    """è§£æSSEæ ¼å¼çš„æ•°æ®æµ"""
    events = []
    text = data.decode("utf-8", errors="replace")

    # æŒ‰è¡Œåˆ†å‰²
    lines = text.split("\n")

    for line in lines:
        line = line.strip()
        if line.startswith("data: "):
            data_content = line[6:]

            if data_content == "[DONE]":
                continue

            try:
                json_data = json.loads(data_content)
                events.append(json_data)
            except json.JSONDecodeError:
                logging.warning(f"Could not decode SSE JSON data: {data_content}")
    return events


def handle_sse_choices(events: List[Dict[str, Any]]) -> str:
    """
    å¤„ç†å’ŒèšåˆSSEäº‹ä»¶æµä¸­çš„æ‰€æœ‰choicesï¼ŒåŒ…æ‹¬æ–‡æœ¬å†…å®¹å’Œå·¥å…·è°ƒç”¨ã€‚

    Args:
        events: è§£æåçš„SSEäº‹ä»¶åˆ—è¡¨ã€‚

    Returns:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²ï¼Œå±•ç¤ºæ‰€æœ‰èšåˆåçš„choiceå†…å®¹ã€‚
    """
    # aggregated_choices çš„ç»“æ„:
    # {
    #   choice_index: {
    #     "content": "...",
    #     "reasoning": "...",
    #     "tool_calls": { tool_call_index: { ... } },
    #     "finish_reason": "...",
    #     "role": "..."
    #   }
    # }
    aggregated_choices: Dict[int, Dict[str, Any]] = {}

    for event in events:
        for choice in event.get("choices", []):
            choice_index = choice.get("index", 0)
            delta = choice.get("delta", {})

            # ç¡®ä¿è¯¥choiceçš„æ¡ç›®å­˜åœ¨
            if choice_index not in aggregated_choices:
                aggregated_choices[choice_index] = {
                    "content": "",
                    "reasoning": "",
                    "tool_calls": {},
                    "finish_reason": "N/A",
                    "role": "N/A",
                }

            current_choice = aggregated_choices[choice_index]

            # èšåˆè§’è‰²
            if delta.get("role"):
                current_choice["role"] = delta.get("role")

            # èšåˆå†…å®¹ (stop)
            if delta.get("content"):
                current_choice["content"] += delta.get("content")

            # èšåˆæ¨ç†å†…å®¹ (reasoning or reasoning_content)
            reasoning = delta.get("reasoning") or delta.get("reasoning_content")
            if reasoning:
                current_choice["reasoning"] += reasoning

            # èšåˆå·¥å…·è°ƒç”¨ (tool_calls)
            if delta.get("tool_calls"):
                for tool_call_chunk in delta.get("tool_calls", []):
                    tool_index = tool_call_chunk.get("index")
                    if tool_index is None:
                        continue  # æ— æ•ˆçš„tool_callå—

                    # ç¡®ä¿è¯¥tool_callçš„æ¡ç›®å­˜åœ¨
                    if tool_index not in current_choice["tool_calls"]:
                        current_choice["tool_calls"][tool_index] = {}

                    current_tool_call = current_choice["tool_calls"][tool_index]

                    # åˆå¹¶ID, type, function name
                    if "id" in tool_call_chunk:
                        current_tool_call["id"] = tool_call_chunk["id"]
                    if "type" in tool_call_chunk:
                        current_tool_call["type"] = tool_call_chunk["type"]
                    if "function" in tool_call_chunk:
                        func = tool_call_chunk["function"]
                        if "name" in func:
                            if "function" not in current_tool_call:
                                current_tool_call["function"] = {}
                            current_tool_call["function"]["name"] = func["name"]
                        # æ‹¼æ¥ arguments
                        if "arguments" in func:
                            if "function" not in current_tool_call:
                                current_tool_call["function"] = {}
                            if "arguments" not in current_tool_call["function"]:
                                current_tool_call["function"]["arguments"] = ""
                            current_tool_call["function"]["arguments"] += (
                                func["arguments"] or ""
                            )

            # è·å–æœ€ç»ˆçš„ finish_reason
            if choice.get("finish_reason"):
                current_choice["finish_reason"] = choice.get("finish_reason")

    # æ ¼å¼åŒ–è¾“å‡º
    choices_result = "## ChoicesğŸ”\n"
    for index, choice_data in sorted(aggregated_choices.items()):
        finish_reason = choice_data.get("finish_reason", "N/A")
        role = choice_data.get("role", "N/A")

        choices_result += f"### ğŸ“‹Choice {index}   [finish_reason: `{finish_reason}`, role:`{role}`]\n"

        # æ˜¾ç¤ºèšåˆçš„æ¨ç†å†…å®¹
        reasoning = choice_data.get("reasoning", "").strip()
        if reasoning:
            choices_result += f"#### ğŸ§  Reasoning\n"
            choices_result += f"{split_line}{indent_text(reasoning, 4)}{split_line}"

        # æ˜¾ç¤ºèšåˆçš„æ–‡æœ¬å†…å®¹
        
        content = choice_data.get("content", "").strip()
        if content:
            choices_result += f"#### âœï¸ Content\n"
            choices_result += f"{split_line}{indent_text(content, 4)}{split_line}"

        # æ˜¾ç¤ºèšåˆçš„å·¥å…·è°ƒç”¨
        tool_calls = choice_data.get("tool_calls", {})
        if tool_calls:
            choices_result += f"#### Tool Calls ({len(tool_calls)})\n"
            for j, tool_call_data in sorted(tool_calls.items()):
                tool_id = tool_call_data.get("id", "N/A")
                tool_type = tool_call_data.get("type", "N/A")
                function = tool_call_data.get("function", {})
                function_name = function.get("name", "N/A")
                arguments = function.get("arguments", "{}")

                choices_result += f"##### ğŸ”¨Tool Call {j}\n"
                choices_result += f"  - ID      : {tool_id}\n"
                choices_result += f"  - Type    : {tool_type}\n"
                choices_result += f"  - Function: {function_name}\n"
                choices_result += f"  - Arguments: {split_line}{indent_text(arguments, 4)}{split_line}"

    return choices_result


class OpenaiRespSSE(Contentview):
    name = "OpenAI SSE Response"
    syntax_highlight = "none"

    def prettify(
        self,
        data: bytes,
        metadata: contentviews.Metadata,
    ) -> str:
        try:
            return self.prettify_exec(data, metadata)
        except Exception as e:
            logging.error(f"Error prettifying SSE response: {e}")
            traceback.print_exc()
            return f"Error during prettifying: {e}\n\n" + data.decode(
                "utf-8", errors="replace"
            )

    def prettify_exec(
        self,
        data: bytes,
        metadata: contentviews.Metadata,
    ) -> str:
        # logging.info('prettify LLM SSE Response body')
        if not isinstance(metadata.http_message, Response):
            return f'"{self.name}" is for LLM SSE Response'

        events = parse_sse_data(data)
        if not events:
            return "# Empty SSE Response or [DONE] only"

        # ä»åå¾€å‰æŸ¥æ‰¾æœ€åä¸€ä¸ªåŒ…å« usage ä¿¡æ¯çš„äº‹ä»¶ï¼Œä½œä¸ºåŸºç¡€ä¿¡æ¯æ¥æº
        # è¿™æ¯”ç®€å•å– a[-1] æ›´å¯é ï¼Œå› ä¸ºæœ€åå‡ ä¸ªäº‹ä»¶å¯èƒ½æ˜¯ç©ºçš„
        final_event_for_meta = None
        for event in reversed(events):
            if "usage" in event and event["usage"] is not None:
                final_event_for_meta = event
                break
        # å¦‚æœæ²¡æ‰¾åˆ°å¸¦ usage çš„ï¼Œå°±ç”¨æœ€åä¸€ä¸ªäº‹ä»¶ä½œä¸ºå…œåº•
        if not final_event_for_meta:
            final_event_for_meta = events[-1]

        result = f"# LLM SSE Response ({len(events)} events) \n \n"

        # 1. å¤„ç†åŸºç¡€ä¿¡æ¯
        result += handle_response_basis(final_event_for_meta)
        result += multi_line_splitter(2)

        # 2. å¤„ç†æ‰€æœ‰èšåˆåçš„ Choices (åŒ…æ‹¬ stop å’Œ tool_calls)
        result += handle_sse_choices(events)
        result += multi_line_splitter(2)

        # 3. å¤„ç†ç³»ç»ŸæŒ‡çº¹
        result += handle_system_fingerprint(final_event_for_meta)

        return result

    def render_priority(self, data: bytes, metadata: contentviews.Metadata) -> float:
        content_type = metadata.content_type or ""
        is_sse = "text/event-stream" in content_type

        # æ›´ç²¾ç¡®åœ°åŒ¹é… OpenAI streaming API è·¯å¾„
        is_openai_stream_path = metadata.flow.request.path.endswith(
            "/chat/completions"
        ) or metadata.flow.request.path.endswith("/completions")

        if (
            isinstance(metadata.http_message, Response)
            and is_openai_stream_path
            and is_sse
        ):
            # æ£€æŸ¥æ˜¯å¦æœ‰ 'data:' æ ‡å¿—ï¼Œè¿›ä¸€æ­¥ç¡®è®¤æ˜¯SSE
            if b"data:" in data[:100]:
                return 2
        return 0


contentviews.add(OpenaiRespSSE)
